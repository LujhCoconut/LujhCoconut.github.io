# HYTE (ISCA'25)

【Title】HYTE: Flexible Tiling for Sparse Accelerators via Hybrid Static-Dynamic Approaches



## Introduction

### 稀疏张量加速器

`sparse-sparse matrix multiplications`

这类加速器通常包含一组

* 乘加运算处理单元（PE）
  * `multiply-accumulate processing elements`
* 以及多级 SRAM 缓冲区。

它们采用专门的数据流方案，对应于张量维度之间的各种迭代顺序，例如内积（Inner Product, IP）、外积（Outer Product, OP）和 Gustavson 方案等。



对于大型稀疏张量，加速器的片上缓冲区可能不足以容纳所有数据，仍然需要对昂贵的片外存储器进行大量的随机数据访问。在这种情况下，分块（tiling）成为一种具有吸引力的解决方案：

* 将张量拆分为多个较小的分块，每个分块能够放入缓冲区中，并在切换到下一个分块之前尽可能在片上进行数据复用。



当前最先进的稀疏加速器尝试通过以下两种方式应对这一难题：

* 一种是采用动态运行时分块技术，灵活调整分块大小 [19, 25]；
* 另一种是利用静态启发式方法，略微超额预订缓冲区空间以提高利用率 [38]。

但遗憾的是，纯动态分块由于实现复杂度较高，其分块决策只能限制在少数几种选项中；而纯静态分块在数据稀疏性变化较大时通常效率较低。

此外，我们发现这些已有设计并未全面探索分块设计的完整空间。它们的许多设计参数

* 包括分块形状
* 分块间的迭代顺序，
* 以及不同操作数张量在 SRAM 缓冲区中的相对空间分配等，

都是固定的，往往并非最优，特别是在张量具有多样化的稀疏模式时。而且，支持分块的元数据（例如，某个分块中压缩后非零数据的起始和结束位置）也可能带来显著的额外开销，需要加速器硬件进行细致的管理。



本文中，我们采用整体性研究方法，深入探讨稀疏张量加速器的分块（tiling）策略，并提出 **HYTE** ——一个静态-动态混合框架，用于实现灵活且高效的稀疏张量分块。HYTE 支持丰富多样的灵活分块参数，包括：分块大小（即每个分块中非零元素的个数）、分块形状（即沿每个张量维度的坐标范围）、相邻分块之间的维度迭代顺序，以及 SRAM 缓冲区的分配策略。

在静态离线阶段，HYTE 依靠一个调度器来分析操作数张量的稀疏模式，通过高效且轻量的采样方法估算若干关键指标。借助一个性能模型，该调度器随后生成一个接近最优的分块方案，并为上述参数设定初始值。我们所采用的采样方法比以往的静态启发式方法 [38] 更为全面，仅需极小的离线开销即可获得更高效的分块结果。

基于该初始分块方案，HYTE 硬件进一步实施动态调优，通过动态收缩或扩展分块大小，即使在局部数据稀疏模式高度变化的情况下，也能始终确保最大化的缓冲区利用率。由于静态调度方案本身已接近最优，因此动态调优过程可以大大简化。此外，HYTE 高效地管理了片外存储器（用于分块间执行）和片上缓冲区（用于分块内执行）中的元数据，并灵活地在数据与元数据之间共享缓冲区空间，从而减轻了元数据带来的复杂性。

我们通过在多种稀疏数据集上与当前最先进的稀疏加速器 [19, 25, 38] 进行对比，对 HYTE 进行了评估。在采用 Gustavson 硬件数据流的代表性稀疏-稀疏矩阵乘法核上，HYTE 的平均速度比基线方法快 **3.3 倍至 6.2 倍**，并且其性能非常接近穷举搜索得到的静态最优方案。大部分性能提升得益于灵活的分块参数选择和高效的静态调度，而我们在硬件中实现的动态特性也能够在静态调度未能找到理想方案的一些极端情况下进一步提升性能。

我们还展示了 HYTE 的性能增益在不同稀疏计算核和不同硬件数据流之间具有一致性。得益于我们高效的采样方法，即使离线调度是在 CPU 上执行的，其开销也非常小。



## Background and Related Work

### Sparse Tensor Algebra

#### **什么是张量和稀疏张量？**

* **张量（Tensor）** 是一种**多维数据数组**，可以理解为矩阵的高维推广：
  * 标量（0维）→ 向量（1维）→ 矩阵（2维）→ 张量（3维及以上）
* **稀疏张量（Sparse Tensor）** 是指其中**绝大多数元素为零的张量**。比如在一个三维张量中，可能只有极少数的(i,j,k)位置上的值是非零的，其余全部是零。
  * 为什么要关注稀疏张量？
  * 因为现实世界中很多数据是稀疏的，比如：
    * 图数据（大部分节点之间没有连接 → 边为0）
    * 推荐系统中的用户-物品交互矩阵（大多数用户没看过大多数商品 → 大量零值）
    * 科学计算中的网格数据（很多区域数值为0）
    * 如果用普通（稠密）方式存储和计算，会浪费大量存储空间和计算资源在那些无意义的零值上。所以我们需要**稀疏表示与稀疏计算优化**。



#### **张量中的“点”与坐标表示**

* 张量中的每一个**非零元素**被称为一个 **点（point）**
  * 每个点由其**坐标（coordinates）唯一确定**
  * 比如在三维张量 **X** 中，一个元素可以表示为 **Xi,j,k**，它的坐标就是 **(i, j, k)**
  * 类比：在二维矩阵里，元素 A[i][j] 的坐标就是 (i, j)
  * 这其实是很直观的，就是用一组数字（坐标）来定位张量中的某个具体值。



#### **稀疏张量上的操作：Einsum 表示法**

* **Einsum（Einstein summation）表示法** 是一种简洁且通用的方式，用来描述张量操作，尤其在深度学习和科学计算中非常流行
  * 它通过一种类似数学公式的符号，清晰表达张量之间的运算，包括**哪些维度被收缩（求和）、哪些被保留**。

$$
A(I\times K)
\newline
B(K\times J)
\newline
C_{i，j}=A_{i,k}\times B_{k,j}
$$

* 公式中的 **k 是“收缩维度”（contracted dimension）**，即在计算过程中，对 k 进行遍历并**累加（aggregate）**乘积结果，最终得到 C[i,j]
  * 对于每一个输出位置 C[i,j]，我们要遍历所有 k，把 A[i,k] * B[k,j] 加起来。但如果 A[i,k] 或 B[k,j] 中有一个是零，这个乘积就是零，可以跳过。
  * 这就是为什么稀疏计算要特别关注**非零元素的分布与访问模式**，以提升效率、减少无效计算。



#### 稀疏张量的存储格式

由于稀疏张量中大部分是零，直接用稠密方式存储（比如一个巨大的多维数组，里面很多零）会非常浪费空间。因此，研究者设计了多种**压缩存储格式**，只存非零部分，常见的有：

* **COO（Coordinate Format）坐标格式**
  * 存储非零元素的**坐标**和**值**
  * 例如：$[(i1,j1,k1, val1), (i2,j2,k2, val2), ...]$
  * 简单直观，但查找效率不高
* **CSR（Compressed Sparse Row） / CSC（Compressed Sparse Column）**
  * 更高效的存储格式，尤其适合**矩阵**（2D张量）
  * CSR：按行压缩，适合按行访问; CSC：按列压缩，适合按列访问
  * 通过几个数组来表示：
    * 非零值数组
    * 列索引（或行索引）
    * 行指针（或列指针）——用来快速定位某一行的起始位置
* **Block CSR 等块变体**
  * 把相邻的多个元素组成“块”，以块为单位存储与计算
  * 适合具有一定局部性的稀疏模式，能提高缓存利用率

> 这些格式本质上都是为了**只存非零数据，同时保留其位置信息与值**，从而节省空间、加速访问。





#### 张量的层级结构：Fibers 与 Positions

在这些压缩存储格式中，张量的各个维度会被组织成一种**层级结构**

其中一个重要的概念是 **fiber**

* 可以理解为：**在某几个维度固定时，另一个维度上的一组连续非零点**
  * 例如，在一个 3D 张量中，如果我们固定 i 和 j，那么 k 方向上的一系列非零点就构成一个 fiber
  * Fiber 是一系列**坐标 + 非零值**的组合，通常是顺序存储的，便于高效访问

**Position（位置）** 指的是该点在**压缩后的存储格式中的实际存储位置**

* 由于我们**压缩掉了零值**，所以某个点在原始坐标系中的坐标（i,j,k）和它在存储中的实际位置（比如内存中的偏移地址）**通常是不一样的**
  * 此外，为了压缩存储，还可能引入很多**空指针或特殊标记**，进一步导致坐标与位置不一致
  * 所以，在设计和优化稀疏计算时，我们需要同时考虑：
    * **逻辑层面：坐标（i,j,k）表示的语义位置**
    * **物理层面：数据在内存中的实际位置（position）**





### Sparse Tensor Accelerators

稀疏张量涉及大量间接且不规则的数据访问，这种访问模式不太适合通用处理器。因此，研究者提出了专门针对稀疏张量的**硬件加速器**，并在**计算数据流（dataflow）**和**数据缓冲区实现**两方面进行了大量优化。



#### **Sparse Dataflow**

与稠密计算场景类似 [16, 39]，稀疏加速器的数据流也可以表示为**多层嵌套循环**，这些循环遍历张量的多维空间。以 **稀疏-稀疏矩阵乘法（SpMSpM）** 为例，它涉及三个维度：**(i, j, k)**，目前主流的稀疏加速器采用了以下三种数据流方案：

* **内积（Inner Product, IP）** [4, 12, 31]：对应的循环顺序为 **i ⊲ j ⊲ k**
* **外积（Outer Product, OP）** [14, 26, 41]：对应的循环顺序为 **k ⊲ i ⊲ j**
* **Gustavson 方案（Gustavson’s, Gust）** [17, 20, 40]：对应的循环顺序为 **i ⊲ k ⊲ j**



这些数据流方案对于三个张量 **A、B、C** 的**数据复用友好性（data reuse friendliness）各不相同**

关键点在于：**数据复用的效果，取决于那些“无关维度”（比如对输出张量 C 而言的 k 维度）在循环顺序中的位置。**

* 当**无关维度被放在内层循环**时，该维度上的数据可以在多次迭代中被重复利用，从而实现**优秀的数据复用性**；
* 反之，如果**无关维度被放在外层循环**，那么该维度上的数据会在每次外层循环时都被重新扫描，不仅无法复用，还会导致**有限的片上缓冲区被频繁“颠簸（thrash）”**，即反复加载相同或相似的数据块，造成效率低下。

认识到这些权衡，一些设计 [20, 24] 支持**运行时动态配置多种数据流**，通过硬件可重构的方式，来适应输入张量**多种多样的稀疏模式**。

> **“无关维度”指的是：在当前的计算目标（比如输出张量 C 的某个位置 C[i,j]）中，对该维度本身并没有直接贡献，但却在循环中被遍历的维度。**
>
> 更具体地说：
>
> 在某个计算目标（比如 C[i,j]）中，**你已经确定了 i 和 j，而 k 是用来“求和/聚合”的维度**，那么对于 **C[i,j] 这个结果元素来说，k 就是一个“无关维度”**。
>
> $C[i,j]=\sum_{k}^{}A[i,k]\times B[k,j] $
>
> 对于 **某个固定的 C[i,j] 而言，k 是一个用来计算它的“工具维度”**，但它**本身并不是 C[i,j] 的索引的一部分**。 所以，**k 就是所谓的“无关维度”**（对于 C[i,j] 的存储与访问来说）。

在循环嵌套中，**维度的排列顺序（即数据流）决定了计算时各个维度是在外层循环还是内层循环**，进而影响：

* **数据的复用性（reuse）**
* **访问的局部性（locality）**
* **缓存/缓冲区的效率**



#### **Buffer Management**

传统的、由硬件管理的**缓存（cache）机制**，对于专用稀疏加速器而言被认为是**低效的**。因此，一种称为 **显式解耦数据编排（Explicit Decoupled Data Orchestration, EDDO）** [21, 27, 30] 的方法，成为了专为加速器设计的缓冲区管理范式。

EDDO 的核心思想是：

* **将计算单元与各级缓冲区解耦**，并且**在每一层缓冲区上，尽可能提前（as far in advance as possible）通过专用的地址生成器（address generators）主动预取数据**；
* 每个缓冲区都使用**独立的地址空间进行显式寻址**，从而**避免了传统缓存中因维护标签（cache tags）所带来的额外开销**；

具体来说：

* 根据所采用的数据流方案，**某些张量（比如非规则访问模式的张量）会以不规则的访问模式被访问**，这些张量应当被**缓冲并复用于片上存储（on-chip buffers）中**，以减少对**昂贵片外存储器（off-chip memory）的频繁访问**；
* 而**另一些张量可能呈现出简单的流式访问模式（streaming pattern），且时间局部性（temporal locality）较弱**，它们**只需占用很小的缓冲区空间即可**。





### Tiling in Sparse Accelerators

为了进一步提高数据复用效率，**分块（tiling）** 成为了稀疏加速器中一种颇具前景的技术。一个 **分块（tile）** 是整个迭代空间（I, J, K）中一个**逻辑上连续的子空间**，代表整体计算任务中的一个子集。**分块的形状（tile shape）** 定义为该分块在每个维度上的坐标跨度，记为 Ti、Tj、Tk；而**分块的大小（tile size）** 则是指该分块中包含的**非零点（non-zero points）的数量**。



通过将**分块大小限制在不超过片上缓冲区容量**的范围内，我们可以在处理当前分块时，**最大化该分块内部的数据复用**，然后再处理下一个分块。然而，分块技术也会带来一些问题，比如：

* **对其他张量的重复访问**
* **额外的部分结果合并开销**
* **以及更加复杂的数据访问模式**

值得注意的是，在大多数稀疏存储格式中，一个维度上的fibers需要根据分块形状进行切分，而这些**fiber segments** 进一步增加了**元数据（metadata）的开销**。



针对稀疏张量的分块技术通常可以分为两大类：**坐标分块（coordinate tiling）** 和 **位置分块（position tiling）**

* **坐标分块（Coordinate Tiling）** 是按照每个维度上相同的坐标跨度来划分数据的。
  * 优点：
    * **坐标对齐（aligned）**：不同 tile 之间的坐标范围要么完全一致，要么完全不重叠 → **简化了计算时的坐标匹配逻辑**
    * 容易理解和实现
  * 缺点：
    * **不同 tile 的实际数据量（非零点数量）可能差别很大**，因为局部稀疏性不同
      * 有的 tile 可能只有几个非零点 → **缓冲区利用不足（underutilization）**
      * 有的 tile 可能非零点太多 → **放不下，导致溢出（overflow）**
    * **难以保证每个 tile 的大小（非零点数量）一致**
* **位置分块（Position Tiling）** 则是根据具体存储格式中实际的数据量，将数据划分为**大小相同的块**。
  * 优点：
    * **每个 tile 的大小（非零点数量）较为均衡**，有助于 buffer 的均衡利用
  * 缺点：
    * **坐标范围不对齐（unaligned）**：不同 tile 的 i,j,k 范围可能是乱七八糟的，难以直接匹配
    * **管理复杂度高**：你需要额外记录每个 tile 的实际坐标范围，增加了调度与访问难度
    * 对 fiber 的切分和 metadata 管理也提出了更高要求



**当前最先进的稀疏加速器分块（tiling）技术**

目前，大多数现有设计采用**坐标分块（coordinate tiling）**，以简化硬件控制逻辑。但同时，这些设计也意识到：**当数据实际大小与片上缓冲区容量不匹配时，会导致效率低下**，因此引入了更加**动态、灵活的分块策略** [19, 25, 38]。

* **Tailors [38]** 采用了一种**推测式策略（speculative strategy）**来确定分块大小，其做法是：**预先对数据的稀疏性进行采样（pre-sampling），并允许一小部分分块（例如 10%）超额预订（overbook）片上缓冲区的容量**。
* 另一方面，**DRT [25]** 和 **HARP [19]** 都使用了**动态调整方法**，在**运行时（runtime）动态调整分块大小**，以便即使面对**变化的数据稀疏特性（varying data sparsity characteristics）**，也能**充分利用片上缓冲区空间**。









