# [VLDB'23]PetPS

**Title:**  PetPS: Supporting Huge Embedding Models with Persistent Memory

**Keywords:** 

**Major Contribution:**



## 本文简介

Embedding Models是学习高维稀疏数据的有效方法。传统上，它们被部署在DRAM Parameter Server(PS）中，用于在线推理访问。然而，不断增加的模型容量使这种做法遭受高存储成本和长恢复时间的影响。快速开发的持久性内存（PM）为PSs提供了新的大容量存储机会，而PM的应用还面临着两个挑战，包括高读取延迟和沉重的CPU负担。为了为在线推断提供一种低成本但仍然具有高性能的参数服务，我们引入了第一个生产部署的PM参数服务器PetPS。(1)为了避免使用较高的PM延迟，PetPS引入了一个为嵌入模型工作负载量身定制的PM哈希索引，以最小化PM访问。(2)为了减轻CPU负担，PetPS将参数收集卸载到网卡上，避免在PM上访问参数时CPU暂停，从而提高CPU效率。

本文的评估表明，与使用最先进的PM哈希索引的PSs相比，PetPS可以提高1.3−1.7×的吞吐量，或者以相同的吞吐量减少2.9−5.5×的延迟。自2020年以来，PetPS已部署在世界领先的短视频公司快手，并在不降低性能的情况下成功降低了30%的TCO（总体拥有成本？？）。



## 相关简介

### Parameter Server

在机器学习和深度学习领域，分布式的优化已经成了一种先决条件。因为单机已经解决不了目前快速增长的数据和参数了。现实中，训练数据的数量可能达到1TB到1PB之间，而训练过程中的参数可能会达到1e9到1e12。而往往这些模型的参数需要被所有的worker节点频繁的访问，这就会带来很多问题和挑战：

* 访问这些巨量的参数，需要大量的网络带宽支持；

* 很多机器学习算法都是连续型的，只有上一次迭代完成（各个worker都完成）之后，才能进行下一次迭代，这就导致了如果机器之间性能差距大（木桶理论），就会造成性能的极大损失；

* 在分布式中，容错能力是非常重要的。很多情况下，算法都是部署到云环境中的（这种环境下，机器是不可靠的，并且job也是有可能被抢占的）；

**通用的分布式系统通常都是：每次迭代都强制同步**，通常在几十个节点上，它们的性能可以表现的很好，但是在大规模集群中，这样的**每次迭代强制同步的机制会因为木桶效应变得很慢**。



parameter server 正是吸取Graphlab采用图形抽象的方式进行异步调度通信的异步机制的优势，并且解决了其在可扩展性方面的劣势。

* 由于是异步的通信，因此，不需要停下来等一些机器执行完一个iteration（除非有必要），这大大减少了延时。为机器学习任务做了一些优化(后续会细讲)，能够大大减少网络流量和开销
* 宽松的一致性要求进一步减少了同步的成本和延时。parameter server 允许算法设计者根据自身的情况来做算法收敛速度和系统性能之间的trade-off。
* 使用了一个分布式hash表使得新的server节点可以随时动态的插入到集合中；因此，新增一个节点不需要重新运行系统。
* 我们都知道，节点故障是不可避免的，特别是在大规模商用服务器集群中。从非灾难性机器故障中恢复，只需要1秒，而且不需要中断计算。Vector clocks 保证了经历故障之后还是能运行良好；
* **全局共享的参数可以被表示**成各种形式：vector，matrices 或者相应的sparse类型，这大大方便了机器学习算法的开发。并且提供的线性代数的数据类型都具有高性能的多线程库。



在parameter server中，每个 server 实际上都只负责分到的**部分参数**（servers共同维持一个全局的共享参数），而每个 work 也只分到**部分数据**和处理任务；

每个子节点都只维护自己分配到的参数，自己部分更新之后，将计算结果（例如：梯度）传回到主节点，进行全局的更新（比如平均操作之类的），主节点再向子节点传送新的参数；



* **具体可以参见知乎 [【深度学习分布式】Parameter Server 详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/21569493)**