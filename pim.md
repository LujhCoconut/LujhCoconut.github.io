# 存内计算/近数据处理

------

**参考文献**： **A Modern Primer on Processing in Memory**

**作者**： **Onur Mutlu** 【ETH Zurich  / Carnegie Mellon University】

​	     **Saugata Ghose** 【Carnegie Mellon University / University of Illinois at Urbana-Champaign】

​	     **Juan Gomez-Luna**【ETH Zurich】

​	     **Rachata Ausavarungnirun** 【King Mongkut’s University of Technology North Bangkok】



------

## Introduction

主存，使用动态随机存取存储器（DRAM）技术构建，是几乎所有计算系统的主要组件，包括服务器、云平台、移动/嵌入式设备和传感器系统。在所有这些系统中，现代应用程序的数据工作集的大小正在迅速增长，而对此类数据的快速分析的需求也在不断增加。因此，主存正在各种计算系统和应用程序中成为一个越来越重要的瓶颈。缓解主存瓶颈需要有效地提高内存容量、能源、成本和性能。不幸的是，近年来，特别是在过去的十年里，要扩展所有这些维度变得越来越困难，因此主存瓶颈正在恶化。

造成主存瓶颈的一个主要原因是与数据移动相关的高能量和延迟成本。在现代计算机中，要对驻留在主存中的数据执行任何操作，处理器必须从主存中检索数据。这就要求内存控制器通过一个相对缓慢且耗电的芯片外总线（称为内存通道memory channel）向DRAM模块发出命令。DRAM模块通过内存通道发送所请求的数据，然后将数据放在缓存和寄存器中。一旦数据在其寄存器中，CPU就可以对数据执行计算。**从DRAM移动到CPU的数据会导致很长时间的延迟，并消耗大量的能量**。CPU 没有重用带到缓存中的许多数据，这对高延迟和能源成本没有什么好处。

**数据移动的成本**是当代计算机系统中**以处理器为中心**的一个基本问题。CPU被认为是系统中的master，计算只在处理器（和加速器）中执行。相比之下，数据存储和通信单元，包括主存储器，被视为无法计算的不智能的工人。由于这种**以处理器为中心的设计范式，数据在系统中的计算单元和通信/存储单元之间大量移动**，以便可以在其上进行计算。随着当代和新兴的应用程序日益以数据为中心的本质，以处理器为中心的设计范例导致了在性能、能源和成本方面的巨大低效。

例如，单个计算节点内的大部分real estate已经专门用于处理数据移动和存储（例如，大型缓存、内存控制器、互连和主存），我们最近的工作表明，移动设备超过**62%**的整个系统能量用于广泛使用的移动工作负载的处理器和存储器层次之间的**数据移动**

现代系统中数据移动的巨大开销，以及技术的进步，使内存和逻辑能够更好地集成，最近促使人们重新审视一个旧的想法，我们通常称之为**存内计算**（processing-in-memory，PIM）。关**键思想是将计算机制放置在数据存储处或附近**（即存储器芯片内部、3d堆叠存储器的逻辑层、存储器控制器中或大缓存内部），以便与当代以处理器为中心的系统相比，在完成计算和存储数据之间的数据移动减少或消除。**processing-in-memory，也称为近数据处理（NDP**），它能够使用**(1)内存本身** 或 (2)**内存子系统内部的某种形式的处理逻辑**（如加速器、简单内核、可重构逻辑）来执行操作和执行软件任务

PIM的想法已经存在了至少50年。然而，由于各种原因，过去的努力并没有被广泛采用，包括**1)将处理元素与DRAM集成的困难**，**2)缺乏当前技术和应用程序所面临的与内存相关的关键扩展挑战**，和3)**数据移动瓶颈对系统成本、能源和性能并不像今天那么重要**。由于现代内存体系结构的进步，例如，以3d堆叠的方式将逻辑和内存进行集成，最近的各种工作探索了一系列具有多个不同目的的PIM体系结构。我们认为，以新的视角（即新的方法和想法），利用新的内存技术，以现实的工作负载和系统的方式和简化采用和可行性的心态，重新检查PIM是至关重要的。

在本章中，我们将探讨在现代系统中实现内存中处理的两种新方法。第一种方法**最小限度地改变内存芯片**，以执行简单而强大的通用操作，这些操作本身效率高，或者可以在执行。我们将这种方法称为**PUM** (processing using memory) 。属于这种方法的一些解决方案利用现有的DRAM设计，使用DRAM的模拟操作原理巧妙而有效地执行批量操作（即操作整个行DRAM单元），如批量复制、数据初始化和位操作。其他解决方案利用新兴的非易失性存储器技术的模拟操作原理来执行类似的批量操作或其他专门的计算，如卷积和矩阵乘法。

第二种方法**通过利用传统存储器控制器或相对较新的3d堆叠存储器技术的逻辑层)中的计算能力**，以更通用的方式实现PIM。我们称这种接近内存的处理的一般方法为。这种方法特别受到3d堆叠存储技术的推动，该技术包括存储层下的逻辑处理层。为了堆叠多层存储器，3d堆叠芯片使用垂直通过硅孔（TSVs）将各层相互连接，并连接到芯片的I/O驱动器。tsv在3D堆栈层内提供了比内存通道外部更大的内部带宽。一些这样的3d堆叠内存架构，如混合内存立方体HMC和高带宽内存HBM，包括一个逻辑层，在那里设计师可以添加一些处理逻辑（例如，加速器，简单的核心，可重新配置的逻辑）来利用这种高内部带宽。未来的die堆叠技术，如*monolithic 3D* ，可以通过极大地**提高内部带宽和内存层之间的逻辑层数量来放大这种方法的好处**。

无论PIM采用何种方法，系统架构师和程序员都必须解决一些关键的实际采用挑战，以使PIM在整个计算领域和工作负载的不同领域中得到广泛采用。除了描述这两种关键方法的工作，我们还在本教程中讨论这些挑战，以及解决这些挑战的现有工作。





## 影响主存的主要趋势

随着现代应用数据工作集大小的增长，对更高的DRAM容量和性能需求也在不断增加。然而，由于DRAM技术的扩展变得越来越具有挑战性，包括难以以低成本扩大DRAM芯片容量，同时保持性能、能效和可靠性。这导致了满足现代工作负载不断增长的内存需求变得越来越昂贵和困难。DRAM技术的扩展影响了DRAM的各项主要特征，包括容量、带宽、延迟、可靠性、能效和成本。因此，这些趋势促使了对智能内存控制器的需求，以更好地实现主存储器在各项指标上的扩展。这些**智能内存控制器**还可以更容易地为内存中的处理铺平道路，并作为PIM的起始基板。这些趋势使得设计低延迟主存储器芯片变得越来越重要，特别是在需要实时处理大量数据的情况下。

有几个key concerns:

* 同时缩放DRAM容量（即密度或每位成本）、带宽和延迟是困难的
* DRAM技术扩展到更小的节点会对DRAM的可靠性产生不利影响。
  * 随着DRAM单元的尺寸减小，电容和接入晶体管都变得更不可靠，更容易泄漏，通常更容易受到电噪声和干扰的影响。
    * 内存技术的缩放会导致内存错误更频繁地出现
* 激进的DRAM技术扩展导致的可靠性问题可能导致新的安全漏洞。
  * 比如RowHammer
    * 重复刷一个DRAM行，改变相邻行
    * 使得可能一个应用程序的页对应的DRAM行持续被刷新导致操作系统的页对应的行发生比特翻转
    * RowHammer攻击可以借此获得一部分内核特权
    * （1）通过JavaScipt远程接管服务器
    * （2）一个虚拟机通过诱导错误来接管另一个虚拟机
    * （3）无权限的应用程序可以控制一个安卓设备
    * （4）攻击者可以通过windows10的浏览器获取任意读写权限
* 主存的能耗
  * DRAM本质上是一种电力和能源消耗器，因为即使不使用它，它也会消耗能源
  * 三个主要的原因导致主存能耗的情况更糟糕
    * 主存的容量、带宽、并行性和复杂性都在增加，由于更高的动态活动量和更高的整体静态功耗，导致能量消耗自然增加
    * 主存仍然是主处理芯片，因此没有受益于许多节能机制有更好的集成
    * DRAM技术扩展的困难使得DRAM节能变得非常困难。事实上，添加到DRAM芯片中的一些机制，以补偿在较小技术的几代中的可靠性问题
      * 纠错机制
      * 高刷新率

因此，相对于计算平台上的其他组件，主存的功耗和能耗正在增加。由于能源效率和可持续性是当今计算平台的关键必需品，因此减少主存的能源和功耗至关重要



## 智能内存控制器来提高内存的扩展的需求

> 解决上述四个主要问题的一个关键方法是设计能够更好地管理主存的智能内存控制器

